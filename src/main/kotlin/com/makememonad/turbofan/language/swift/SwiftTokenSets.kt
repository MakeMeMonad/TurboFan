package com.makememonad.turbofan.language.swift

import com.intellij.psi.tree.TokenSet
import com.makememonad.turbofan.language.swift.psi.SwiftTypes
import com.makememonad.turbofan.language.swift.psi.SwiftTypes.*


object SwiftTokenSets {
    val ALL_KEYWORDS = TokenSet.create(
        KW_PND_AVAILABLE, KW_PND_COLORLITERAL, KW_PND_ELSE, KW_PND_ELSEIF, KW_PND_ENDIF, KW_PND_FILELITERAL, KW_PND_IF, KW_PND_IMAGELITERAL, KW_PND_KEYPATH, KW_PND_SELECTOR, KW_PND_SOURCELOCATION, KW_PND_UNAVAILABLE, KW_UPPER_ANY, KW_LOWER_ANY, KW_ASSOCIATEDTYPE, KW_AWAIT, KW_BORROWING, KW_BREAK, KW_CASE, KW_CLASS, KW_CONSUMING, KW_CONTINUE, KW_DEFAULT, KW_DEFER, KW_DEINIT, KW_DO, KW_ELSE, KW_ENUM, KW_EXTENSION, KW_FALLTHROUGH, KW_FALSE, KW_FILEPRIVATE, KW_FOR, KW_FUNC, KW_GUARD, KW_IF, KW_IMPORT, KW_IN, KW_INIT, KW_INOUT, KW_INTERNAL, KW_LET, KW_NIL, KW_NONISOLATED, KW_OPEN, KW_OPERATOR, KW_PRECEDENCEGROUP, KW_PRIVATE, KW_LOWER_PROTOCOL_DECL, KW_PUBLIC, KW_REPEAT, KW_RETURN, KW_LOWER_SELF, KW_UPPER_SELF, KW_STATIC, KW_STRUCT, KW_SUPER, KW_SWITCH, KW_SUBSCRIPT, KW_THROWS, KW_TRUE, KW_TRY, KW_TYPEALIAS, KW_VAR, KW_WHERE, KW_WHILE, KW_CATCH, KW_THROW, KW_RETHROWS, KW_ASSOCIATIVITY, KW_ASYNC, KW_CONVENIENCE, KW_DIDSET, KW_DYNAMIC, KW_FINAL, KW_GET, KW_INDIRECT, KW_INFIX, KW_LAZY, KW_LEFT, KW_MUTATING, KW_NONE, KW_NONMUTATING, KW_OPTIONAL, KW_OVERRIDE, KW_PACKAGE, KW_POSTFIX, KW_PRECEDENCE, KW_PREFIX, KW_UPPER_PROTOCOL, KW_REQUIRED, KW_RIGHT, KW_SET, KW_SOME, KW_UPPER_TYPE, KW_UNOWNED, KW_WEAK, KW_WILLSET
    )
    val ALL_IDENTIFIERS = TokenSet.create(
        SwiftTypes.IDENTIFIER
    )
    val NUMBERS: TokenSet
        get() = TokenSet.orSet(/* ...sets = */ this.INTEGERS, this.FLOATS)
    val STRINGS: TokenSet
        get() = TokenSet.orSet(/* ...sets = */this.SINGLELINE_STRINGS, this.MULTILINE_STRINGS)
    // TODO: Fill this out with all other Operator tokens emitted by the lexer. Remove any PSI-only tokens..?
    val ALL_OPERATORS = TokenSet.create(
        SwiftTypes.OPERATOR, DOT_OPERATOR, PREFIX_OPERATOR, INFIX_OPERATOR, POSTFIX_OPERATOR
    )
    // TODO: Figure out doc-string comments, get a rule in place for those and a token as well...
    val ALL_LITERALS = TokenSet.orSet(this.STRINGS, this.NUMBERS, this.OTHER_LITERALS)
    val ALL_COMMENTS: TokenSet
        get() = TokenSet.orSet(/* ...sets = */ this.SINGLELINE_COMMENTS, this.MULTILINE_COMMENTS)
    val OTHER_LITERALS: TokenSet
        get() = TokenSet.orSet(/* ...sets = */ this.REGEXP, this.BOOLEANS, this.NILS)
    val INTEGERS = TokenSet.create(
        INTEGER_LITERAL, HEX_LITERAL, OCTAL_LITERAL, BINARY_LITERAL
    )
    val FLOATS = TokenSet.create(
        HEX_FLOATING_POINT_LITERAL, DECIMAL_FLOATING_POINT_LITERAL
    )
    val SINGLELINE_STRINGS = TokenSet.create(
        STRING_START, STRING_TEXT, STRING_END
    )
    val MULTILINE_STRINGS = TokenSet.create(
        MULTILINE_STRING_START, MULTILINE_STRING_TEXT, MULTILINE_STRING_END
    )
    val SINGLELINE_COMMENTS = TokenSet.create(
        SINGLELINE_COMMENT, COMMENT_TEXT
    )
    val MULTILINE_COMMENTS = TokenSet.create(
        MULTILINE_COMMENT_START, MULTILINE_COMMENT_TEXT, MULTILINE_COMMENT_END
    )
    val REGEXP = TokenSet.create(REGULAR_EXPRESSION_LITERAL)
    val BOOLEANS = TokenSet.create(KW_TRUE, KW_FALSE)
    val NILS = TokenSet.create(KW_NIL)

    }